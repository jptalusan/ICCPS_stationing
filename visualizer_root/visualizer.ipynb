{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkConf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# spark = SparkSession.builder.config('spark.executor.cores', '8').config('spark.executor.memory', '80g')\\\n",
    "#         .config(\"spark.sql.session.timeZone\", \"UTC\").config('spark.driver.memory', '80g').master(\"local[26]\")\\\n",
    "#         .appName(\"wego-daily\").config('spark.driver.extraJavaOptions', '-Duser.timezone=UTC').config('spark.executor.extraJavaOptions', '-Duser.timezone=UTC')\\\n",
    "#         .config(\"spark.sql.datetime.java8API.enabled\", \"true\").config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "#         .config(\"spark.sql.autoBroadcastJoinThreshold\", -1)\\\n",
    "#         .config(\"spark.driver.maxResultSize\", 0)\\\n",
    "#         .config(\"spark.shuffle.spill\", \"true\")\\\n",
    "#         .config(\"spark.driver.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true\")\\\n",
    "#         .config(\"spark.executor.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true\")\\\n",
    "#         .config(\"spark.ui.showConsoleProgress\", \"false\")\\\n",
    "#         .getOrCreate()\n",
    "# spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from keplergl import KeplerGl\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load inrix segment data\n",
    "# fp = '/home/jptalusan/wego-occupancy/data/backup_trip_traffic_df/inrix_speed_30M_resampled_2021_8.gz'\n",
    "# traffic_estimate_df = pd.read_parquet(fp, engine='auto')\n",
    "\n",
    "# fp = os.path.join('/home/jptalusan/wego-occupancy/data/inrix_grouped.pkl')\n",
    "# with open(fp, \"rb\") as fh:\n",
    "#   inrix_segment_df = pickle.load(fh)\n",
    "\n",
    "# inrix_segment_df = inrix_segment_df.set_geometry('geometry')\n",
    "# inrix_segment_df = inrix_segment_df[inrix_segment_df['County_inrix'] == 'davidson']\n",
    "# # inrix_segment_df = inrix_segment_df.to_crs(\"EPSG:4326\")\n",
    "# traffic_estimate_df = traffic_estimate_df[traffic_estimate_df.measurement_tstamp.dt.day == 23]\n",
    "# traffic_estimate_df = traffic_estimate_df.merge(inrix_segment_df[['geometry', 'XDSegID']], left_on='xd_id', right_on='XDSegID')\n",
    "# traffic_estimate_df = gpd.GeoDataFrame(traffic_estimate_df, geometry='geometry')\n",
    "# # traffic_estimate_df = traffic_estimate_df.to_crs(\"EPSG:3310\")\n",
    "# # traffic_estimate_df['geometry'] = traffic_estimate_df['geometry'].apply(lambda x: reverse_geom(x))\n",
    "# traffic_estimate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '/home/jptalusan/gits/mta_simulator_redo/code_root/scenarios/baseline/data/stops_node_matching.pkl'\n",
    "stops_info = pd.read_pickle(fp)\n",
    "stops_info.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get service disruption dataset\n",
    "fp = '/home/jptalusan/gits/mta_simulator_redo/code_root/scenarios/baseline/data/Service Disruptions_07_2019_08_2022.csv'\n",
    "disruptions_df = pd.read_csv(fp)\n",
    "disruptions_df.head()\n",
    "disruptions_df['DATETIME'] = disruptions_df['DATE'] + ' ' + disruptions_df['TIME']\n",
    "disruptions_df['DATE'] = pd.to_datetime(disruptions_df['DATE'], format='%m/%d/%y', errors='coerce')\n",
    "disruptions_df['TIME'] = pd.to_datetime(disruptions_df['TIME'], format='%H:%M:%S', errors='coerce')\n",
    "disruptions_df['DATETIME'] = pd.to_datetime(disruptions_df['DATETIME'], format='%m/%d/%y %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Remove weather related disruptions\n",
    "# disruptions_df = disruptions_df[(disruptions_df['REASON'] != 'Weather')].sort_values(by=['DATETIME']).reset_index(drop=True)\n",
    "print('Shape:', disruptions_df.shape)\n",
    "# disruptions_df = disruptions_df.drop(columns=['COMMENTS'])\n",
    "disruptions_df['BLOCK'] = disruptions_df['BLOCK'].astype('int32')\n",
    "\n",
    "# Convert to spark dataframe for merging\n",
    "# disruptions_sp = spark.createDataFrame(disruptions_df)\n",
    "# disruptions_sp = disruptions_sp.withColumn(\"BLOCK\", F.col(\"BLOCK\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = map_1.config\n",
    "# with open('/home/jptalusan/gits/mta_simulator_redo/code_root/scenarios/baseline/output/config.json', 'w') as fp:\n",
    "#     json.dump(config, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '../code_root/visualizer.csv'\n",
    "viz_df = pd.read_csv(fp)\n",
    "viz_df = viz_df.fillna(method='backfill').sort_values(by='time')\n",
    "viz_df = pd.merge(viz_df, stops_info[['stop_id_original', 'map_latitude', 'map_longitude']], left_on='last_visited_stop', right_on='stop_id_original')\n",
    "# viz_df = viz_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df = viz_df.drop_duplicates()\n",
    "viz_df.to_csv('visualizer_processed_break_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1 = KeplerGl(height=800)\n",
    "map_1.add_data(viz_df, name='buses')\n",
    "map_1.add_data(disruptions_df, name='disruptions')\n",
    "with open('/home/jptalusan/gits/mta_simulator_redo/code_root/scenarios/baseline/output/config.json', 'r') as fp:\n",
    "    config = json.load(fp)\n",
    "map_1.config = config\n",
    "    \n",
    "# map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here nashville shapes\n",
    "from shapely.geometry import shape\n",
    "df = pd.read_json('here.nashville.shapes.json')\n",
    "df['geometry'] = df['geom'].apply(lambda x: shape(x))\n",
    "df = df.drop(['_id', 'geom'], axis=1)\n",
    "gdf = gpd.GeoDataFrame(df)\n",
    "gdf = gdf.set_geometry('geometry')\n",
    "gdf['geom_type'] = 'MultiLineString'\n",
    "gdf.to_file(\"nashville_HERE.geojson\", driver='GeoJSON')\n",
    "gdf = gpd.read_file(\"nashville_HERE.geojson\")\n",
    "map_1 = KeplerGl(height=800)\n",
    "map_1.add_data(gdf, name='here_shapes')\n",
    "map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88d12193eb5d2fbe298f9bb9e457ac6a535b56551d0f537fc14a1636657a2895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
